{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T17:15:57.997389Z",
     "start_time": "2025-03-04T17:15:57.581449Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "\n",
    "\n",
    "def t_distribution_pdf(x, nu):\n",
    "    coeff = gamma((nu + 1) / 2.0) / (np.sqrt(nu * np.pi) * gamma(nu / 2))\n",
    "    density = coeff * (1 + x ** 2 / nu) ** (-0.5 * (nu + 1))\n",
    "    return density\n",
    "\n",
    "\n",
    "def mean(data_points):\n",
    "    return np.sum(data_points) / len(data_points)\n",
    "\n",
    "\n",
    "def standard_deviation_of_means(data_points):\n",
    "    return np.sqrt(np.sum((data_points - mean(data_points)) ** 2) / (len(data_points) - 1)) / np.sqrt(len(data_points))\n",
    "\n",
    "\n",
    "def find_t_critical(confidence_level, nu, x_start=0, x_end=20, num_points=10000):\n",
    "    # keep adding to the integral until reading t_critical for which the integral = 0.95\n",
    "    x = np.linspace(x_start, x_end, num_points)\n",
    "    y = t_distribution_pdf(x, nu)\n",
    "    cdf = np.cumsum(y) * (x[1] - x[0])  # works bc all dx same size and this is what a loop would do\n",
    "    target_half_prob = confidence_level / 2\n",
    "    index = np.where(cdf >= target_half_prob)[0][0]\n",
    "    return x[index]\n",
    "\n",
    "\n",
    "def calculate_t_score(sample_mean, population_mean, sample_standard_deviation):\n",
    "    return (sample_mean - population_mean) / sample_standard_deviation\n",
    "\n",
    "\n",
    "def hypothesis_test_1(data_points, population_mean, confidence_level):\n",
    "    sample_mean = mean(data_points)\n",
    "    sample_std_dev = standard_deviation_of_means(data_points)\n",
    "    t_critical = find_t_critical(confidence_level, len(data_points) - 1)\n",
    "    t_score = calculate_t_score(sample_mean, population_mean, sample_std_dev)\n",
    "\n",
    "    return abs(t_score) <= t_critical\n",
    "\n",
    "\n",
    "def hypothesis_test_2(data_points, population_mean, confidence_level):\n",
    "    sample_mean = mean(data_points)\n",
    "    sample_std_dev = standard_deviation_of_means(data_points)\n",
    "    t_critical = find_t_critical(confidence_level, len(data_points) - 1)\n",
    "    t_score = calculate_t_score(sample_mean, population_mean, sample_std_dev)\n",
    "    \n",
    "    if abs(t_score) > t_critical:\n",
    "        if t_score > 0:\n",
    "            return 1  # if mu > mu_naught\n",
    "        else:\n",
    "            return -1  # if mu < mu_naught\n",
    "    else:\n",
    "        return 0  # if mu = mu_naught\n",
    "\n",
    "\n",
    "math_test_scores = [92.64, 79.00, 84.79, 97.41, 93.68, 65.23, 84.50, 73.49, 73.97, 79.11]\n",
    "\n",
    "hypothesis_test_1_result = hypothesis_test_1(math_test_scores, 75, 0.95)\n",
    "hypothesis_test_2_result = hypothesis_test_2(math_test_scores, 75, 0.95)\n",
    "\n",
    "if not hypothesis_test_1_result:\n",
    "    if hypothesis_test_2_result == 1:\n",
    "        print(\"Beneficial!\")\n",
    "    elif hypothesis_test_2_result == -1:\n",
    "        print(\"Detrimental!\")\n",
    "else:\n",
    "    print(\"No one cares!\")\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficial!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ec5dc27244856d85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
